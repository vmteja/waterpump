{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 23 columns):\n",
      "days_since_recorded      59400 non-null int64\n",
      "funder                   59400 non-null int64\n",
      "installer                59400 non-null int64\n",
      "longitude                59400 non-null float64\n",
      "latitude                 59400 non-null float64\n",
      "basin                    59400 non-null int64\n",
      "region_code              59400 non-null int64\n",
      "district_code            59400 non-null int64\n",
      "lga                      59400 non-null int64\n",
      "population               59400 non-null int64\n",
      "public_meeting           59400 non-null int64\n",
      "permit                   59400 non-null int64\n",
      "construction_year        59400 non-null int64\n",
      "extraction_type_class    59400 non-null int64\n",
      "management               59400 non-null int64\n",
      "management_group         59400 non-null int64\n",
      "payment                  59400 non-null int64\n",
      "water_quality            59400 non-null int64\n",
      "quantity                 59400 non-null int64\n",
      "source                   59400 non-null int64\n",
      "source_class             59400 non-null int64\n",
      "waterpoint_type          59400 non-null int64\n",
      "status_group             59400 non-null int64\n",
      "dtypes: float64(2), int64(21)\n",
      "memory usage: 10.4 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import scipy.stats as scipy\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "train = r\"C:\\Users\\Krishna Teja\\Documents\\Study Material\\267 - Tran\\evaluation\\trainingdata.csv\"\n",
    "test = r\"C:\\Users\\Krishna Teja\\Documents\\Study Material\\267 - Tran\\evaluation\\testingdata.csv\"\n",
    "\n",
    "train = pd.read_csv(train)\n",
    "test = pd.read_csv(test)\n",
    "columnsToEncode = list(train.select_dtypes(include=['category','object']))\n",
    "le = preprocessing.LabelEncoder()\n",
    "train[\"funder\"]=train[\"funder\"].astype(str)\n",
    "train[\"installer\"]=train[\"installer\"].astype(str)\n",
    "train[\"basin\"]=train[\"basin\"].astype(str)\n",
    "train[\"lga\"]=train[\"lga\"].astype(str)\n",
    "train[\"public_meeting\"]=train[\"public_meeting\"].astype(str)\n",
    "train[\"permit\"]=train[\"permit\"].astype(str)\n",
    "train[\"extraction_type_class\"]=train[\"extraction_type_class\"].astype(str)\n",
    "train[\"management\"]=train[\"management\"].astype(str)\n",
    "train[\"management_group\"]=train[\"management_group\"].astype(str)\n",
    "train[\"payment\"]=train[\"payment\"].astype(str)\n",
    "train[\"water_quality\"]=train[\"water_quality\"].astype(str)\n",
    "train[\"quantity\"]=train[\"quantity\"].astype(str)\n",
    "train[\"source\"]=train[\"source\"].astype(str)\n",
    "train[\"source_class\"]=train[\"source_class\"].astype(str)\n",
    "train[\"waterpoint_type\"]=train[\"waterpoint_type\"].astype(str)\n",
    "#merged_data['date_recorded']=merged_data['date_recorded'].astype(str)\n",
    "#print (merged_data.funder.value_counts())\n",
    "#merged_data[\"feature\"] = le.fit_transform(merged_data[\"funder\"])\n",
    "for feature in columnsToEncode:\n",
    "    try:\n",
    "         train[feature] = le.fit_transform(train[feature])\n",
    "    except:\n",
    "         print('Error encoding '+feature)\n",
    "\n",
    "            \n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47520 entries, 55424 to 2732\n",
      "Data columns (total 22 columns):\n",
      "days_since_recorded      47520 non-null int64\n",
      "funder                   47520 non-null int64\n",
      "installer                47520 non-null int64\n",
      "longitude                47520 non-null float64\n",
      "latitude                 47520 non-null float64\n",
      "basin                    47520 non-null int64\n",
      "region_code              47520 non-null int64\n",
      "district_code            47520 non-null int64\n",
      "lga                      47520 non-null int64\n",
      "population               47520 non-null int64\n",
      "public_meeting           47520 non-null int64\n",
      "permit                   47520 non-null int64\n",
      "construction_year        47520 non-null int64\n",
      "extraction_type_class    47520 non-null int64\n",
      "management               47520 non-null int64\n",
      "management_group         47520 non-null int64\n",
      "payment                  47520 non-null int64\n",
      "water_quality            47520 non-null int64\n",
      "quantity                 47520 non-null int64\n",
      "source                   47520 non-null int64\n",
      "source_class             47520 non-null int64\n",
      "waterpoint_type          47520 non-null int64\n",
      "dtypes: float64(2), int64(20)\n",
      "memory usage: 8.3 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data=train.ix[ :, train.columns != 'status_group']\n",
    "target1=train['status_group']\n",
    "train1,test1,train2,test2=train_test_split(data,target1,test_size=0.2,random_state=0)\n",
    "train1.info();\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807575757576\n",
      "0.807575757576\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators = 150)\n",
    "# Fit the training data to the Survived labels and create the decision trees\n",
    "forest = forest.fit(train1,train2)\n",
    "\n",
    "# Take the same decision trees and run it on the test data\n",
    "predicted_classification = forest.predict(test1)\n",
    "print(forest.score(test1,test2))\n",
    "\n",
    "print(accuracy_score(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751346801347\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.92      0.81      6444\n",
      "          1       0.64      0.13      0.21       867\n",
      "          2       0.83      0.63      0.72      4569\n",
      "\n",
      "avg / total       0.76      0.75      0.73     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier().fit(train1,train2)\n",
    "predicted_classification = clf.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "clf=GradientBoostingClassifier()\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789814814815\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83      6444\n",
      "          1       0.46      0.34      0.39       867\n",
      "          2       0.81      0.78      0.80      4569\n",
      "\n",
      "avg / total       0.78      0.79      0.79     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=1.2, n_estimators=500, max_depth=10).fit(train1,train2)\n",
    "predicted_classification = clf.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790151515152\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.85      0.83      6444\n",
      "          1       0.44      0.35      0.39       867\n",
      "          2       0.82      0.79      0.80      4569\n",
      "\n",
      "avg / total       0.78      0.79      0.79     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=1.5, n_estimators=400, max_depth=20, random_state=3421).fit(train1,train2)\n",
    "predicted_classification = clf.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant = 0.5\n",
      "Penalty = l1\n",
      "0.600589225589\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.69      0.67      6444\n",
      "          1       0.23      0.21      0.22       867\n",
      "          2       0.58      0.55      0.57      4569\n",
      "\n",
      "avg / total       0.60      0.60      0.60     11880\n",
      "\n",
      "Penalty = l2\n",
      "0.591077441077\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.21      0.23       867\n",
      "          2       0.57      0.54      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Constant = 1.0\n",
      "Penalty = l1\n",
      "0.602356902357\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.69      0.67      6444\n",
      "          1       0.23      0.21      0.22       867\n",
      "          2       0.59      0.56      0.57      4569\n",
      "\n",
      "avg / total       0.60      0.60      0.60     11880\n",
      "\n",
      "Penalty = l2\n",
      "0.591161616162\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.21      0.23       867\n",
      "          2       0.57      0.54      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Constant = 1.5\n",
      "Penalty = l1\n",
      "0.600505050505\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.69      0.67      6444\n",
      "          1       0.23      0.21      0.22       867\n",
      "          2       0.58      0.55      0.57      4569\n",
      "\n",
      "avg / total       0.60      0.60      0.60     11880\n",
      "\n",
      "Penalty = l2\n",
      "0.591077441077\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.21      0.23       867\n",
      "          2       0.57      0.54      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "for c in [0.5,1.0,1.5]:\n",
    "    print \"Constant =\", c\n",
    "    for p in ['l1','l2']:\n",
    "        print \"Penalty =\", p\n",
    "        clf=LogisticRegression(solver='liblinear', penalty=p, class_weight='balanced', C=c, random_state=321)\n",
    "        clf.fit(train1, train2)\n",
    "        predicted_classification = clf.predict(test1)\n",
    "        print(accuracy_score(test2, predicted_classification))\n",
    "        print(classification_report(test2, predicted_classification))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant = 0.5\n",
      "Penalty = l1\n",
      "0.593097643098\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Penalty = l2\n",
      "0.591498316498\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.55      4569\n",
      "\n",
      "avg / total       0.58      0.59      0.59     11880\n",
      "\n",
      "Constant = 1.0\n",
      "Penalty = l1\n",
      "0.593097643098\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Penalty = l2\n",
      "0.592760942761\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.55      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Constant = 1.5\n",
      "Penalty = l1\n",
      "0.593013468013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Penalty = l2\n",
      "0.59132996633\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.55      4569\n",
      "\n",
      "avg / total       0.58      0.59      0.59     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "for c in [0.5,1.0,1.5]:\n",
    "    print \"Constant =\", c\n",
    "    for p in ['l1','l2']:\n",
    "        print \"Penalty =\", p\n",
    "        clf=LinearSVC(dual=False, penalty=p, class_weight='balanced', C=c, random_state=321)\n",
    "        clf.fit(train1, train2)\n",
    "        predicted_classification = clf.predict(test1)\n",
    "        print(accuracy_score(test2, predicted_classification))\n",
    "        print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.52      0.58      6444\n",
      "          1       0.18      0.43      0.25       867\n",
      "          2       0.56      0.58      0.57      4569\n",
      "\n",
      "avg / total       0.59      0.54      0.55     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "predicted_classification = OneVsRestClassifier(LinearSVC(dual=False, penalty='l1', class_weight='balanced', C=1.0, random_state=321)).fit(train1,train2).predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant = 1.0\n",
      "Penalty = l1\n",
      "0.593097643098\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Penalty = l2\n",
      "0.592760942761\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.55      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Constant = 10\n",
      "Penalty = l1\n",
      "0.593013468013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Penalty = l2\n",
      "0.592760942761\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.55      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Constant = 15\n",
      "Penalty = l1\n",
      "0.593013468013\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.20      0.22       867\n",
      "          2       0.57      0.54      0.56      4569\n",
      "\n",
      "avg / total       0.59      0.59      0.59     11880\n",
      "\n",
      "Penalty = l2\n",
      "0.591414141414\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.68      0.66      6444\n",
      "          1       0.24      0.19      0.22       867\n",
      "          2       0.57      0.54      0.55      4569\n",
      "\n",
      "avg / total       0.58      0.59      0.59     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "for c in [1.0,10,15]:\n",
    "    print \"Constant =\", c\n",
    "    for p in ['l1','l2']:\n",
    "        print \"Penalty =\", p\n",
    "        clf=LinearSVC(dual=False, penalty=p, class_weight='balanced', C=c, random_state=321)\n",
    "        clf.fit(train1, train2)\n",
    "        predicted_classification = clf.predict(test1)\n",
    "        print(accuracy_score(test2, predicted_classification))\n",
    "        print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.547727272727\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.53      0.60      6444\n",
      "          1       0.17      0.42      0.24       867\n",
      "          2       0.57      0.59      0.58      4569\n",
      "\n",
      "avg / total       0.60      0.55      0.57     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "predicted_classification = OneVsRestClassifier(LinearSVC(dual=False, penalty='l2', class_weight='balanced', C=1.0, random_state=321)).fit(train1,train2).predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725673400673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.90      0.79      6444\n",
      "          1       0.51      0.05      0.09       867\n",
      "          2       0.79      0.61      0.68      4569\n",
      "\n",
      "avg / total       0.72      0.73      0.70     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "reg = AdaBoostClassifier().fit(train1,train2)\n",
    "predicted_classification=reg.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.736279461279\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.89      0.80      6444\n",
      "          1       0.47      0.07      0.13       867\n",
      "          2       0.78      0.64      0.71      4569\n",
      "\n",
      "avg / total       0.73      0.74      0.71     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "param={\"n_estimators\":[100,250,350], \"learning_rate\":[0.5,1,1.5], \"random_state\":321 }\n",
    "n=10\n",
    "\n",
    "reg = AdaBoostClassifier(n_estimators=150, ).fit(train1,train2)\n",
    "random_search=RandomizedSearchCV(reg, param_distributions=param, n_iter=n)\n",
    "predicted_classification=reg.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792508417508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.83      6444\n",
      "          1       0.47      0.36      0.41       867\n",
      "          2       0.82      0.78      0.80      4569\n",
      "\n",
      "avg / total       0.79      0.79      0.79     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.5, n_estimators=500, max_depth=30, random_state=3421).fit(train1,train2)\n",
    "predicted_classification = clf.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732154882155\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.91      0.79      6444\n",
      "          1       0.50      0.04      0.08       867\n",
      "          2       0.80      0.62      0.70      4569\n",
      "\n",
      "avg / total       0.73      0.73      0.70     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "reg = AdaBoostClassifier(n_estimators=250, learning_rate=0.5)\n",
    "reg.fit(train1,train2)\n",
    "predicted_classification=reg.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.739393939394\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.88      0.80      6444\n",
      "          1       0.40      0.10      0.17       867\n",
      "          2       0.78      0.66      0.71      4569\n",
      "\n",
      "avg / total       0.72      0.74      0.72     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "reg = AdaBoostClassifier(n_estimators=250, learning_rate=1.5)\n",
    "reg.fit(train1,train2)\n",
    "predicted_classification=reg.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742424242424\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.88      0.80      6444\n",
      "          1       0.44      0.12      0.19       867\n",
      "          2       0.78      0.66      0.72      4569\n",
      "\n",
      "avg / total       0.73      0.74      0.72     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "reg = AdaBoostClassifier(n_estimators=450, learning_rate=1.5)\n",
    "reg.fit(train1,train2)\n",
    "predicted_classification=reg.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737205387205\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.91      0.80      6444\n",
      "          1       0.52      0.05      0.10       867\n",
      "          2       0.80      0.63      0.70      4569\n",
      "\n",
      "avg / total       0.73      0.74      0.71     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "reg = AdaBoostClassifier(n_estimators=450, learning_rate=0.5)\n",
    "reg.fit(train1,train2)\n",
    "predicted_classification=reg.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79234006734\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.83      6444\n",
      "          1       0.46      0.36      0.41       867\n",
      "          2       0.82      0.78      0.80      4569\n",
      "\n",
      "avg / total       0.79      0.79      0.79     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=1.5, n_estimators=500, max_depth=30, random_state=3421).fit(train1,train2)\n",
    "predicted_classification = clf.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.52      0.58      6444\n",
      "          1       0.18      0.43      0.25       867\n",
      "          2       0.56      0.58      0.57      4569\n",
      "\n",
      "avg / total       0.59      0.54      0.55     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "predicted_classification = OneVsRestClassifier(LinearSVC(dual=False, penalty='l1', class_weight='balanced', C=1.0, random_state=321)).fit(train1,train2).predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.550420875421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "predicted_classification = OneVsOneClassifier(LinearSVC()).fit(train1.values,train2).predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79797979798\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.84      6444\n",
      "          1       0.48      0.36      0.41       867\n",
      "          2       0.83      0.79      0.81      4569\n",
      "\n",
      "avg / total       0.79      0.80      0.79     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.5, n_estimators=500, max_depth=30, random_state=3421, warm_start=True,loss='deviance', max_features=12, min_samples_split=2).fit(train1,train2)\n",
    "predicted_classification = clf.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.535521885522\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.56      0.61      6444\n",
      "          1       0.13      0.28      0.17       867\n",
      "          2       0.54      0.55      0.54      4569\n",
      "\n",
      "avg / total       0.59      0.54      0.56     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.5, n_estimators=300, max_depth=20, random_state=3421, warm_start=True,loss='deviance', max_features=4, min_samples_split=6, min_samples_leaf=6,subsample=0.8).fit(train1,train2)\n",
    "predicted_classification = clf.predict(test1)\n",
    "print(accuracy_score(test2, predicted_classification))\n",
    "print(classification_report(test2, predicted_classification))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
